{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognite contextualization lab 1 - Entity Matching\n",
    "Estimated time: 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get access to CDF\n",
    "We assume you have some basic knowledge of CDF and the SDK. If not, please follow the 'lab' tutorials first.\n",
    "\n",
    "Unlike previous tutorials, for this application you *must* have access to a Cognite project / tenant, you can apply for one [here](https://cognitedata.atlassian.net/wiki/spaces/CSF/pages/1113523070/Creating+a+new+tenant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "We need to import some Python modules in order to interact with CDF. We will use the Python SDK with Experimental Extensions, which we below refer to as a `client`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from cognite.experimental import CogniteClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get access to your project, replace `yourproject` with your project name in the next cell. If you are using a production tenant, remove 'server=greenfield'.\n",
    "When you create the `CogniteClient` below, `getpass` will ask for your API key in an extra password field. Simply paste it in and press shift+enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CogniteClient(\n",
    "    api_key=getpass(\"Please enter API key: \"),\n",
    "    project=\"yourproject\",\n",
    "    server=\"greenfield\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some example entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_to = [\n",
    "    {\"id\": 1, \"name\": \"ENTITY_MATCHING_FUN_314\"},\n",
    "    {\"id\": 2, \"name\": \"ENTITY_MATCHING_INTERESTING_42\"},\n",
    "    {\"id\": 3, \"name\": \"ENTITY_MATCHING_CONFUSING_123\"},\n",
    "    {\"id\": 4, \"name\": \"CONFUSING_NON_123_MATCHING\"},\n",
    "]\n",
    "entities_from = [{\"id\": 100, \"name\": \"INTERESTING_SENSOR_42\"},\n",
    "                 {\"id\": 200, \"name\": \"SENSOR_CONFUSING_123\"},\n",
    "                 {\"id\": 300, \"name\": \"FUN_314_SENSOR_SHOULD_GIVE_NON_MATCH_123\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Entity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "em = client.entity_matching.fit_ml(match_from=entities_from, match_to=entities_to)\n",
    "em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can run predict on the model object and it will wait for it to be ready and submit the predict job. \n",
    "Likewise, asking for the result will wait for it. Since it only waits when necessary, you can both work interactively as well as easily submit a large number of jobs to be processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = em.predict_ml(match_from=entities_from, num_matches=2)\n",
    "job.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `SENSOR_CONFUSING_123` and `FUN_314_SENSOR_SHOULD_GIVE_NON_MATCH_123` both have two matches with identical score. Let's try a different model type which prefers tokens in the same pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = client.entity_matching.fit_ml(match_from=entities_from, match_to=entities_to,model_type='bigram')\n",
    "job = em.predict_ml(num_matches=2)\n",
    "job.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the top match is as expected! There are a number of different models and classifiers, but for many applications, the 'bigram' model strikes a good balance between performance and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also use CDF resources directly to run entity matching, specify fields to match on, and fill in missing fields with an empty string\n",
    "This assumes you have some interesting assets and time series in your tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = client.assets.list(limit=10)\n",
    "time_series = client.time_series.list(limit=10)\n",
    "em = client.entity_matching.fit_ml(match_from=time_series, match_to=assets, keys_from_to=[('externalId','externalId'),('description','description')], model_type='bigram', complete_missing=True)\n",
    "em.predict_ml().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
